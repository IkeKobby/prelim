

----- Page 1 -----

The American Statistician
ISSN: 0003-1305 (Print) 1537-2731 (Online) Journal homepage: www.tandfonline.com/journals/utas20
A Survey on Large Language Model-based Agentsfor Statistics and Data ScienceMaojun Sun, Ruijian Han, Binyan Jiang, Houduo Qi, Defeng Sun, YanchengYuan & Jian HuangTo cite this article: Maojun Sun, Ruijian Han, Binyan Jiang, Houduo Qi, Defeng Sun, YanchengYuan & Jian Huang (16 Oct 2025): A Survey on Large Language Model-based Agents forStatistics and Data Science, The American Statistician, DOI: 10.1080/00031305.2025.2561140To link to this article:  https://doi.org/10.1080/00031305.2025.2561140
© 2025 The Author(s). Published withlicense by Taylor & Francis Group, LLC.
View supplementary material 
Published online: 16 Oct 2025.
Submit your article to this journal 
Article views: 1501
View related articles 
View Crossmark data
Citing articles: 1 View citing articles 
Full Terms & Conditions of access and use can be found athttps://www.tandfonline.com/action/journalInformation?journalCode=utas20

----- Page 2 -----

THE AMERICAN STATISTICIAN2025, VOL. 00, NO. 0, 1–14: Statistical Computing and Graphicshttps://doi.org/10.1080/00031305.2025.2561140A Survey on Large Language Model-based Agents for Statistics and Data ScienceMaojun Suna,R u i j i a nH a na,B i n y a nJ i a n ga,H o u d u oQ ia,b, Defeng Suna,Y a n c h e n gY u a nb,a n dJ i a nH u a n ga,baDepartment of Data Science and Arti/f_icial Intelligence, The Hong Kong Polytechnic University, Hung Hom, Kowloon, Hong Kong;bDepartment of AppliedMathematics, The Hong Kong Polytechnic University, Hung Hom, Kowloon, Hong KongABSTRACTIn recent years, data science agents powered by Large Language Models (LLMs), known as “data agents,”have shown signi/f_icant potential to transform the traditional data analysis paradigm. This survey providesan overview of the evolution, capabilities, and applications of LLM-based data agents, highlighting theirrole in simplifying complex data tasks and lowering the entry barrier for users without related expertise. Weexplore current trends in the design of LLM-based frameworks, detailing essential features such as planning,reasoning, re/f_lection, multi-agent collaboration, user interface, knowledge integration, and system design,which enable agents to address data-centric problems with minimal human intervention. Furthermore,we analyze several case studies to demonstrate the practical applications of various data agents in real-world scenarios. Finally, we identify key challenges and propose future research directions to advance thedevelopment of data agents into intelligent statistical analysis software.ARTICLE HISTORYReceived December 2024Accepted August 2025KEYWORDSData agents; Data analysis;Generative AI; Naturallanguage interaction;Statistical software1. IntroductionAs nearly every aspect of society becomes digitized, data analysishas emerged as an indispensable tool across various industries(Inala et al.2024). For instance, /f_inancial institutions leveragedata analysis to make informed decisions about stock trends(Institute2011;P r o v o s ta n dF a w c e t t2013), hospitals use itto monitor patients’ health conditions (Waller and Fawcett2016), and companies employ it to develop strategic plans(Chen, Chiang, and Storey2012). Despite its widespread utility,data analysis is o/f_ten perceived as a challenging /f_ield with asigni/f_icant “entry barrier” (Jordan and Mitchell2015; Cao2017),typically requiring knowledge in areas such as statistics, datascience, and computer science (Kitchin2014). Since the releaseof SPSS (IBM1968) in 1968, followed by SAS (Inc.1976),Matlab (MathWorks1984), Excel (Microso/f_t1985), Python(Foundation1991), R (for Statistical Computing1995), PowerBI(Microso/f_t2013), and other specialized data analysis tools andprogramming languages, these advancements have signi/f_icantlyaided professionals in conducting statistical experiments anddata analysis. Moreover, they have made data analysis moreaccessible to a broader range of practitioners (Witten, Frank,and Hall2016).The general data analysis process typically involves severalkey steps. Initially, data is collected from studies or extractedfrom databases and imported into tools such as Excel. Next, so/f_t-ware like Excel or programming languages such as Python andR are employed to clean and analyze the data, aiming to extractvaluable insights. Subsequently, data visualization is performedCONTACTYancheng Yuanyancheng.yuan@polyu.edu.hkDepartment of Applied Mathematics, The Hong Kong Polytechnic University, Hung Hom, Kowloon,Hong Kong; Jian Huangj.huang@polyu.edu.hkDepartment of Applied Mathematics, The Hong Kong Polytechnic University, Hung Hom, Kowloon, Hong Kong.Supplementary materials for this article are available online. Please go towww.tandfonline.com/r/TAS.to make these insights more accessible and understandable. Formore complex tasks, such as statistical inference and predic-tive analysis, statistical and machine learning models are o/f_tennecessary. This involves data processing, feature engineering,modeling, evaluation, and more. Upon completing the analysis,a /f_inal report is usually dra/f_ted to summarize the /f_indings andinsights. However, for individuals without expertise in statistics,data science, and programming, data analysis remains a high-barrier task.The barriers to data analysis primarily exist in the followingareas:• Lack of systematic statistical training: Individuals without abackground in statistics may /f_ind it challenging to under-stand which types of analysis are feasible, even when data ispresented to them. As data and models become increasinglycomplex, gaining a solid understanding of current statisticaltechniques typically requires at least a Master’s level of statis-tical training.• So/f_tware limitation: Simple data analysis tools like Excel areinadequate for complex scenarios, such as predictive analy-sis or analyzing data from enterprise databases. Conversely,advanced programming languages for data analysis, such asPython and R, require prior programming knowledge, whichcan be a barrier for many users.• Challenges in domain-speci/f_ic problems: In specialized /f_ieldslike protein or genetic data analysis, general data scientistsmay /f_ind it diﬃcult to perform eﬀective analysis due to a lackof domain-speci/f_ic knowledge.© 2025 The Author(s). Published with license by Taylor & Francis Group, LLC.This is an Open Access article distributed under the terms of the Creative Commons Attribution-NonCommercial-NoDerivatives License (http://creativecommons.org/licenses/by-nc-nd/4.0/), whichpermits non-commercial re-use, distribution, and reproduction in any medium, provided the original work is properly cited, and is not altered, transformed, or built upon in any way. The terms onwhich this article has been published allow the posting of the Accepted Manuscript in a repository by the author(s) or with their consent.

----- Page 3 -----

2M. SUN ET AL.•D i ﬃ c u l t y i n i n t e g r a t i n g d o m a i n k n o w l e d g e : C o r r e s p o n d i n gto the last point, domain experts o/f_ten lack the data sci-ence and programming skills needed to quickly incorporatetheir expertise into data analysis tools. For example, PSAAM(Steﬀensen, Dufault-Thompson, and Zhang2016)i ss o /f_t w a r edesigned for the curation and analysis of metabolic models,yet a biologist researching metabolism might /f_ind it challeng-ing to integrate this analytical method into common dataanalysis tools like Excel or R.With the rise of generative AI, new opportunities haveemerged in statistics and data science. LLM-based data agentsare gradually addressing existing challenges while introducing anew paradigm for approaching data analysis tasks.An “ AI agent” (or LLM agent) refers to an autonomous orsemi-autonomous so/f_tware system powered by AI models suchas LLMs. These agents can interpret natural language instruc-tions, plan and execute tasks, and interact with users or othersystems to complete complex work%ows (Cheng et al.2024).Speci/f_ically, we de/f_ine an LLM-based data agent as anautonomous or semi-autonomous so/f_tware system powered byLLMs, capable of understanding natural language instructions,planning and executing data-centric tasks, and interactingwith users or external tools to accomplish complex objectives-from exploratory data analysis to machine learning modeldevelopment. In this article, the terms “LLM-based data scienceagent, ” “LLM-based data agent, ” and “data science agent” arecollectively referred to as “data agent” for simplicity.This survey explores recent advancements in data agents andhighlights data analysis performed by various agents throughas e r i e so fc a s es t u d i e s .I nSection 2,w eb r i e % yd i s c u s st h eopportunities introduced by recent developments in generativeAI.Section 3reviews and categorizes recent work on data sci-ence agents. We then present several case studies inSection 4.Section 5examines the challenges and future directions in this/f_ield, followed by our discussion inSection 6.F i n a l l y ,w ep r e s e n tour conclusions inSection 7.2. Opportunities Brought by Generative AIThe rise and potential of generative AI, particularly Large Lan-guage Models (LLMs) or vision language models (VLMs) in the/f_ield of data science and analysis have gained increasing recog-nition in recent years. In addition to understand text, LLMs arealso trained to understand tabular data, allowing them to eﬀec-tively extract insights, identify patterns, and draw meaningfulconclusions from tables (Dong and Wang2024). Consequently,LLMs have emerged as powerful tools capable of signi/f_icantlyenhancing and transforming a variety of data-driven applica-tions and work%ows (Nejjar et al.2023;T ue ta l .2023;C h e n g ,L i ,and Bing2023). Recent research has focused on designing LLM-based data science agents (data agents) to automatically addressdata science tasks through natural language, as demonstrated bytools like ChatGPT-Advanced Data Analysis (ChatGPT-ADA)(OpenAI2023), LAMBDA (Sun et al.2024)a n dC o l a bD a t aScience Agent (Google2025).The emergence of data agents oﬀers a potential solution to thepreviously mentioned challenges, as they lower the entry barrierfor users who lack programming or statistical knowledge. Byproviding an intuitive interface that harnesses the capabilitiesof LLMs, users can request analyses using natural language, andthe data agents can interpret these instructions, access relevantdata, and autonomously apply appropriate analytical techniques.For example, a user might request, “Calculate the sales growthin diﬀerent regions from 2021 to 2028, generate a bar chartto visualize the results, and provide key insights. ” With thissimpli/f_ied instruction, data agents can automatically extract,analyze, visualize, and report data, reducing the requirement fortechnical expertise and fostering a more eﬃcient work%ow. Thissigni/f_icantly lowers the entry barriers for individuals unfamiliarwith traditional data analysis tools and methods.Furthermore, by embedding specialized knowledge intoLLMs, data agents can potentially overcome challenges faced bydata scientists in /f_ields like genomics, where domain expertiseis crucial (Cao2017). Simultaneously, domain experts whomay lack data science or programming skills can rely ondata agents to seamlessly integrate their expertise into dataanalysis work%ows. This ability to bridge the gap betweendomain expertise and data science has the potential to advanceinterdisciplinary research and decision-making in complexscenarios (Figure 1).3. LLM-based Data Science Agents3.1. OverviewLLM-based data agents leverage the powerful natural lan-guage understanding and generation capabilities of LLMs toautonomously tackle complex data analysis tasks.Figure 3illustrates a commonly used framework for these agents.In this framework, the LLM serves as the core of the entiresystem, driving its performance and reliability. As such, thecapabilities of the LLM are critical to the system’s eﬀectiveness,with advanced models like GPT-4 o/f_ten being used. Data analy-sis typically involves multiple steps, especially when addressingcomplex tasks. Techniques such as Planning, Reasoning, andRe%ection help ensure that the LLM processes these tasks withgreater logical coherence and makes optimal use of its knowl-edge.In the architecture, the LLM generates the code for a givendata analysis task, executes it, and retrieves the correspondingresults. This requires an execution environment, represented bythe Sandbox, which safely isolates the code execution process.The Sandbox allows users to run programs and access /f_ileswithout risking the underlying system or platform. It includespre-installed programming environments and so/f_tware, such asPython, R, Jupyter, and SQL Server.Au s e r - f r i e n d l yi n t e r f a c ei sa l s oe s s e n t i a lt oi m p r o v i n gu s a b i l -ity. An intuitive interface not only attracts users but also enablesthem to quickly engage with and use the system eﬀectively.3.2. Evolution of Data Science AgentResearch on data agents began gaining momentum in 2023.Chandel et al. (2022)t r a i n e da n de v a l u a t e dam o d e lw i t h i naJupyter Notebook to predict code based on given commandsand results. Soon a/f_ter, it was discovered that LLMs, such asGPT, could generate accurate code for basic data analysis. With

----- Page 4 -----

THE AMERICAN STATISTICIAN3
Figure 1.New paradigm of data analysis brought by generative AI.
Figure 2.Timeline of selected related works from 2023.the rise of the LLM-based agent, researchers began designingspecial data agents for automating data science and analysis tasksby human language.Figure 2shows some selected works from2023, whileTable 1illustrates some key characteristics.3.3. User InterfaceThe user interface is crucial for attracting users at /f_irst glance.Current research on user interface design can be broadly cate-gorized into four types: Integrated Development Environment-based (IDE-based), Independent System, Command line-based(Command-based), and Operation System-based (OS-based).IDE-based.Integrated Development Environments (IDEs)such as Jupyter provide convenient tools for data scienceand analysis. Recent eﬀorts, including Colab Data ScienceAgent (Google2025), Jupyter-AI (jupyterlab2023), Chapyter(chapyter2023), and MLCopilot (Zhang et al.2023a), haveincorporated LLMs into Jupyter environments. For example,Colab Data Science Agent enables planning, automatic code cellgeneration, execution, and result presentation in the notebook.This approach is particularly popular because it allows users toreview, edit, and run code directly.Independent System.Some works have focused on developingindependent systems equipped with user interfaces. For exam-ple, ChatGPT introduced a streamlined, intuitive conversationalsystem-a model of interaction that has been widely adopted insubsequent projects. In the context of data analysis tasks, beyond

----- Page 5 -----

4M. SUN ET AL.
Figure 3.An architecture of an LLM-based data agent. The diagram illustrates the interaction between LLMs and a sandbox environment. On the left, key components ofLLMs are highlighted, including User Interface, Planning, Reasoning, Re/f_lection, and Error Handling. The sandbox, positioned centrally, serves asac o n t r o l l e de n v i r o n m e n tfor executing task codes and generating results. On the right, various tools and software that can be pre-installed in the sandbox, such as Python, SQL,J u p y t e r ,a n dR ,indicate the diverse ecosystems where LLM-powered agents can operate.Table 1.Characteristics of selected data agents.Data agents Methods User interface Planning Human in the loop Self-correcting ExpandableChatGPT-ADA (OpenAI2023)C o n v e r s a t i o n a l S y s t e m L i n e a rData Copilot (Zhang et al.2023b)E n d - t o - e n d S y s t e m L i n e a rJupyter AI (jupyterlab2023) Conversational IDE-based Basic IOMLCopilot (Zhang et al.2023a) Conversational IDE-based Basic IOChapyter (chapyter2023) Conversational IDE-based Basic IOOpenagents (Xie et al.2023)C o n v e r s a t i o n a l S y s t e m L i n e a rJarviX (Chen et al.2024)E n d - t o - e n d – – – – –DS-Agent (Guo et al.2024)E n d - t o - e n d C L I L i n e a r–Spider2-V (Cao et al.2024)E n d - t o - e n d O S - B a s e d ––ChatGLM-DA (GLM2024)C o n v e r s a t i o n a l S y s t e m L i n e a rTaskWeaver (Qiao et al.2023)E n d - t o - e n d C L I & S y s t e m L i n e a rData Interpreter (Hong et al.2024) End-to-end CLI Hierarchical LAMBDA (Sun et al.2024) Conversational System Basic IO Data Formulator 2 (Wang et al.2024a) Conversational System Basic IO–AutoM3L (Luo et al.2024)E n d - t o - e n d – ––SELA (Chi et al.2024) End-to-end CLI Hierarchical–AIDE (Jiang et al.2024) End-to-end CLI Hierarchical–AutoKagle (Li et al.2024)E n d - t o - e n d C L I L i n e a r AutoML-Agent (Trirat, Jeong, and Hwang2024)E n d - t o - e n d – L i n e a r ––Agent K v1.0 (Grosnit et al.2024)E n d - t o - e n d – L i n e a r –GPT-4o (OpenAI2024)E n d - t o - e n d S y s t e m –AutoGen Studio (Wu et al.2023)E n d - t o - e n d S y s t e m L i n e a rColab Data Science Agent (Google2025) End-to-end IDE-based LinearNOTE: Methods can be categorized into Conversational and End-to-End approaches. Conversational methods support interactive dialogue with iterative user feedback,whereas End-to-End approaches rely on a single prompt, with the agent autonomously planning and solving the problem. The user interface can be categorized into IDE-based, Systems, CLI, and OS-based. The term “Human-in-the-Loop”indicatesthat humans can intervene in the data agent’s work/f_low, such as modifying code in situationswhere automatic processes are inadequate. “Self-Correcting”refers to the agent’s ability to automatically identify and correct errors within thework/f_low through re/f_lection.Finally, “Expandable”denotes the data agent’s capacity to incorporate customized tools or knowledge. “–”indicates that the attribute is either notm e n t i o n e di nt h ea r t i c l eor could not be observed from the provided resources.basic text-based input and output, several systems have intro-duced specialized features, such as visualization, report gener-ation, and /f_ile download options, to simplify user interactions.For instance, LAMBDA (Sun et al.2024) facilitates easy datareview by enabling intuitive data display a/f_ter users upload theirdata. Data Formulator 2 (Wang et al.2024a)f u r t h e re n h a n c e st h eiterative process of creating data visualizations through a multi-modal interface, combining graphical user interface (GUI) ele-ments with natural language inputs, allowing users to specifytheir visualization intentions with both precision and %exibility.WaitGPT (Xie et al.2024)a d d r e s s e st h ec h a l l e n g eo fu n d e r -standing and verifying LLM-generated code by transformingraw code into an interactive, step-by-step visual representation.This allows users to comprehend, validate, and adjust speci/f_icdata operations, actively guiding and re/f_ining the analysis pro-cess.Command Line-based.Works like Data Interpreter (Hong et al.2024) and TaskWeaver (Qiao et al.2023)u s i n gc o m m a n d - l i n einterfaces (CLI) in their works. For researchers and experiencedusers, it provides greater %exibility and control over the system,allowing users to execute a wide range of functions in thecommand line and customize their actions. Besides, command-based interfaces o/f_ten require less computational overheadcompared to graphical user interfaces, making them moreeﬃcient.OS-based.OS-based agents, such as UFO (Zhang et al.2024),are designed to operate directly within an operating system envi-ronment, allowing them to control a wide range of system tasksand resources. Similarly, Spider2-V (Cao et al.2024)s i m u l a t e sthe typical work%ow of a data scientist by mimicking actionssuch as clicking, typing, and writing code, providing an OS-level interactive experience that closely resembles how humansmanage data science tasks. However, while OS-based agents likeSpider2-V lay a solid foundation for user interaction, achievingfull automation of the data science work%ow remains an ongoingchallenge (Cao et al.2024).

----- Page 6 -----

THE AMERICAN STATISTICIAN5
Figure 4.Commonly used planning and reasoning strategies in LLM-based data agents for organizing tasks or solving problems. Each node represents a sub-task int h eroadmap.3.4. Planning, Reasoning, and Re/f_lectionPlanning, Reasoning, and Re%ection o/f_ten play crucial rolesin guiding the actions of data agents. In particular, planningand reasoning emphasize the generation of a logically struc-tured sequence or roadmap of actions and thought processesto systematically address problems step by step (Huang et al.2024b;H o n ge ta l .2024). Complex tasks o/f_ten require a step-by-step approach to ensure eﬀective resolution, while simpler taskscan be handled without such detailed breakdowns. Recently,GPT-4o (OpenAI2024)i n t r o d u c e sap l a n n i n ga r c h i t e c t u r et h a tintegrates external tools and decomposes complex tasks intostructured sub-tasks, enabling more accurate and controllablemulti-step reasoning.Some approaches focus on building conversational dataagents (Zhang et al.2023a,2023b;S u ne ta l .2024), where usersinteract with the agent over multiple rounds to complete a task.In these cases, under human supervision, complex planning isnot necessary, as guidance can simplify decision-making andadjust the work%ow dynamically. Some of these works operatein a Basic I/O mode. On the other hand, End-to-end data agents(Qiao et al.2023;G u oe ta l .2024;H o n ge ta l .2024;C h ie ta l .2024;J i a n ge ta l .2024;L ie ta l .2024;T r i r a t ,J e o n g ,a n dH w a n g2024;G r o s n i te ta l .2024) are designed to allow users to issueas i n g l ep r o m p tt h a te n c o m p a s s e sa l lr e q u i r e m e n t s .I nt h e s ecases, the agent employs planning, reasoning, and re%ection toiteratively complete all tasks autonomously.Recent research in planning has introduced two mainapproaches: Linear Structure Planning (or Single Path Plan-ning/Reasoning) and Hierarchical Structure Planning (orMultiple Path Planning/Reasoning).Figure 4illustrates somerecent planning methodologies like Chain-of-Thought (CoT)(Wei et al.2022), ReAct (Yao et al.2022), Tree-of-Thoughts(ToT) (Yao et al.2024), and Graph-of-Thoughts (GoT) (Bestaet al.2024).Linear Structure Planning.In linear structure planning, a taskis decomposed into a sequential, step-by-step process. For exam-ple, DS-Agent (Guo et al.2024)u s e sC a s e - B a s e dR e a s o n i n gt oretrieve and adapt relevant insights from a knowledge base ofpast successful Kaggle solutions. This approach allows the agentto learn from previous experiences and continuously improveits performance. Similarly, AutoML-Agent (Trirat, Jeong, andHwang2024) adopts a retrieval-augmented planning (RAP)strategy to generate diverse plans for AutoML tasks. By lever-aging the knowledge embedded in LLMs, information retrievedfrom external APIs, and user requirements, RAP allows theagent to explore a wider range of potential solutions, leading tomore optimal plans.Hierarchical Structure Planning.Simple linear planning iso/f_ten insuﬃcient for complex tasks. Such tasks may requirehierarchical and dynamic, adaptable plans that can accountfor unexpected issues or errors in execution (Hong et al.2024). For instance, Hong et al. (2024)u s e sah i e r a r c h i c a lgraph modeling approach that breaks down intricate datascience problems into manageable sub-problems, representedas nodes in a graph, with their dependencies as edges.This structured representation enables dynamic task man-agement and allows for real-time adjustments to evolvingdata and requirements. Additionally, they further introduce“Programmable Node Generation, ” to automate the gen-eration, re/f_inement, and veri/f_ication of nodes within thegraph, ensuring accurate and robust code generation. AIDE(Jiang et al.2024)e m p l o y sS o l u t i o nS p a c eT r e eS e a r c ht oiteratively improve solutions through generation, evaluation,and selection components. Similarly, SELA (Chi et al.2024)combines LLMs with Monte Carlo Tree Search (MCTS) toenhance AutoML performance. It starts by using LLMs togenerate insights for various machine learning stages, creatinga search space for solutions. MCTS then explores this space byiteratively selecting, simulating, and back-propagating feedback,enabling the discovery of optimal pipelines. Agent K v1.0(Grosnit et al.2024) employs a structured reasoning frameworkwith memory modules, operating through multiple phases.The /f_irst phase, automation, handles data preparation andtask setup, generating actions through structured reasoning.The second phase, optimization, involves solving tasks andenhancing performance using techniques such as Late-FusionModel Generation and Bayesian optimization. The /f_inal phase,generalization, uses a memory-driven system for adaptive taskselection.Re/f_lection.Re%ection enables an agent to evaluate past actionsand decisions, adjust strategies, and improve future taskperformance. This process is essential for self-correction anddebugging during task execution. For example, Wang et al.(2024b) employs trajectory /f_iltering to train agents that can learnfrom interactions and enhance their self-debugging capabilities.This technique involves selecting trajectories in which themodel initially makes errors but successfully corrects themthrough self-re%ection in subsequent interactions. Similarly,Data-copilot (Zhang et al.2023b)a n dL A M B D A( S u ne ta l .2024) use self-re%ection based on code execution feedbackto address errors. If a compilation error occurs, the agents

----- Page 7 -----

6M. SUN ET AL.repeatedly attempt to revise the code until it runs successfully ora maximum retry limit is reached. This iterative process helpsensure code correctness and usability.3.5. Multi-Agent CollaborationMulti-agent System (MAS) enable task decomposition throughrole assignment. In this setup, agents communicate, negotiate,and share information to optimize their collective performance(Xi et al.2023). It oﬀers several advantages over single-agentsetups. First, they reduce redundant and complex context accu-mulation by isolating responsibilities across agents. Second, eachagent instance can be powered by a diﬀerent language model,opening opportunities to specialize models for domain-speci/f_icexpertise. For example, in LAMBDA (Sun et al.2024), a ded-icated Programmer Agent is responsible for code generation,while noisy error outputs are handled separately by an Inspec-tor Agent. This separation helps the Programmer Agent avoidcontext overload, simpli/f_ies historical trace management, andultimately improves response accuracy.AutoGen introduces a programming framework speci/f_icallydesigned for constructing MAS (Wu et al.2023). Furthermore,AutoML-Agent (Trirat, Jeong, and Hwang2024)i n v o l v e st h eAgent Manager, Prompt Agent, Operation Agent, Data Agent,and Model Agent-that together cover the entire pipeline, fromdata retrieval to model deployment. OpenAgents (Xie et al.2023)c o n s i s t e do fa g e n t ss u c ha st h eD a t aA g e n t ,P l u g i n sA g e n t ,and Web Agent. Similarly, AutoKaggle (Li et al.2024)e m p l o y sagents like Reader, Planner, Developer, Reviewer, and Summa-rizer to manage each phase of the process, ensuring comprehen-sive analysis, eﬀective planning, coding, quality assurance, anddetailed reporting. These collaborating mode help decentralizedthe complicated task, allowing each agent to focus on its speci/f_icrole, thereby enhancing the overall eﬃciency and eﬀectivenessof the data analysis process.3.6. Knowledge IntegrationIntegrating domain-speci/f_ic knowledge into data agents presentsa challenge (Dash et al.2022;S u ne ta l .2024). For example, whena domain expert has specialized knowledge, such as speci/f_icprotein analysis code, the agent system are expected able toincorporate and apply this knowledge eﬀectively. One approachis tool-based, where the expert’s analysis code is treated as atool that is recognizable by the LLM (Xie et al.2023). When theagent encounters a relevant problem, it can call upon the appro-priate tool from its library to execute the specialized analysis.Another method involves the Retrieval-Augmented Generation(RAG) technique (Lewis et al.2020), where relevant code is /f_irstretrieved and then embedded within the context to facilitate in-context learning. LLM-based agents can also access and interactwith external knowledge sources, such as databases or knowl-edge graphs, to augment their reasoning capabilities (Wang et al.2024b).Sun et al. (2024)p r o p o s e saK n o w l e d g eI n t e g r a t i o nm e t h o dthat builds on this concept. In LAMBDA, analysis codes areparsed into two parts: descriptions and executable code. Theseare then stored in a knowledge base. When the agent receives atask, it retrieves the relevant knowledge based on the similaritybetween the task description and the descriptions stored in theknowledge base. The corresponding code is then used for in-context learning (ICL) or back-end execution, depending onthe con/f_iguration. This approach enables agents to eﬀectivelyleverage domain-speci/f_ic knowledge in relevant scenarios.3.7. Benchmarks for Evaluating Data AgentsEvaluating the performance of data agents is crucial for under-standing their eﬀectiveness and reliability. Current benchmarksprimarily rely on deterministic output comparisons, wherean LLM processes a task, generates code, and is evaluatedbased on the /f_inal execution results. For example, DS-1000 (Laiet al.2023)p r o v i d e sal a r g e - s c a l eb e n c h m a r ko f1 0 0 0r e a l i s t i cproblems spanning seven core Python data science libraries,with execution-based multi-criteria evaluation and mechanismsto reduce memorization bias. MLAgentBench (Huang et al.2024a) introduces a benchmark focused on machine learningresearch work%ows by constructing an LLM-agent pipeline.Furthermore, In/f_iAgent-DABench (Hu et al.2024)p r e s e n t sae n d - t o - e n db e n c h m a r kf o re v a l u a t i n gt h ec a p a b i l i t i e so fdata agents, the tasks require agents to end-to-end solvingcomplex tasks by interacting with an execution environment.However, for tasks such as data visualization, the outputs areo/f_ten diﬃcult to compare directly. Designing eﬀective evaluationstrategies for data visualizations remains an open and importantquestion.3.8. System Design and Other Related WorksRecent advancements in interactive data science systems high-light a variety of approaches in system design, with LLMs andstructured frameworks signi/f_icantly enhancing the user experi-ence across key areas such as data visualization, task speci/f_ica-tion, predictive modeling, and data exploration. Notable systemslike VIDS (Hassan, Knipper, and Santu2023), Data-Copilot(Zhang et al.2023b), InsightPilot (Ma et al.2023), and JarviX(Liu et al.2023)e x e m p l i f yd i v e r s ed e s i g np r i n c i p l e st a i l o r e dto these speci/f_ic functions. For instance, Data-Copilot adopts acode-centric approach, generating intermediate code to processdata and subsequently transforming it into visual outputs, suchas charts, tables, and summaries (Zhang et al.2023b).Other frameworks emphasize work%ow automation. Insight-Pilot integrates an “insight engine” that guides data exploration,reducing LLM hallucinations and enhancing the accuracy ofexploratory tasks (Ma et al.2023). JarviX, in combination withMLCopilot (Zhang et al.2023a), contributes to automatedmachine learning by merging LLM-driven insights withAutoML pipelines. Additionally, in the domain of databasemanagement, systems like LLMDB (Zhou, Zhao, and Li2024)improve eﬃciency and reduce hallucinations and computationalcosts during tasks such as query rewriting, database diagnosis,and data analytics. In terms of data visualization, MatPlotAgent(Yang et al.2024)t r a n s f o r m sr a wd a t ai n t oc l e a r ,i n f o r m a t i v evisualizations by leveraging both code-based and multi-modalLLMs.Moreover, Data Formulator 2 (Wang et al.2024a) organizesuser interactions into “data threads” to provide context andfacilitate the exploration and revision of prior steps. A similarapproach is seen in WaitGPT (Xie et al.2024), which transforms

----- Page 8 -----

THE AMERICAN STATISTICIAN7
Figure 5.Partial dialogue from the ChatGPT-Advanced Data Analysis in CaseS t u d y1 .I t e m s1 – 4l i s tt h ew o r kd o n eb yC h a t G P Ti ne a c hs t e p .raw code into an interactive visual representation. This providesa step-by-step visualization of LLM-generated code in real-time,allowing users to understand, verify, and modify individual dataoperations. SEED (Chen et al.2024)c o m b i n e sL L M sw i t hm e t h -ods like code generation and small models to produce domain-speci/f_ic data curation solutions. HuggingGPT (Shen et al.2024),on the other hand, uses LLMs to coordinate a variety of expertmodels from platforms such as Hugging Face, solving a broaderrange of AI tasks across multiple modalities.Lastly, in terms of industry applications, lots of companieshave used agents in the business analysis. For example FUTUuse AI to analyze the stock market and provide investmentadvice (FUTU2024). Julius (Julius2025) facilitates data scienceeducation by building a bridge that allowing professors to createinteractive work%ows for lessons, which can be shared withstudents for a seamless teaching experience through naturallanguage interaction.4. Data Analysis Through Natural LanguageInteraction: Case StudiesIn this section, we present a series of case studies conducted bya diverse range of agents, each illustrating the new data anal-ysis paradigm facilitated through natural language interaction.These case studies demonstrate how this approach enables usersto engage with data more intuitively and eﬀectively, breakingdown traditional barriers to data accessibility and understand-ing. By leveraging natural language processing, these agents caninterpret and respond to complex queries, providing insightsthat are both comprehensive and easily digestible. Through theseexamples, we aim to highlight the transformative potential ofnatural language interaction in data analysis.4.1. Case Study 1: Exploratory Data Analysis and ModelBuilding by Conversational Data AgentsIn this case study, we used ChatGPT and LAMBDA to demon-strate exploratory data analysis (EDA) and a simple model build-ing process. Speci/f_ically, we /f_irst used ChatGPT to explore theeﬀect of alcohol content on the quality of diﬀerent types ofwine, focusing on both red and white varieties. Then, we usedLAMBDA to illustrate an interactive modeling process and auto-matically generate analysis reports.We used the Wine Quality dataset, a tabular dataset withdimension 4898×11. The goal is to examine how 10 covari-ates in this dataset aﬀect the wine quality rating. We employedChatGPT-ADA to conduct EDA and visualize the in%uence ofalcohol content on wine quality ratings.Figure 5illustrates thedetailed planning and problem-solving process.GPT-ADA /f_irst analyzed the problems and then outlined astep-by-step plan to solve the tasks. The entire work%ow pro-ceeded smoothly, with the code running eﬃciently to load thedata, check for missing values, and generate visualizations, witheach step delivering accurate results. Its ability to interpret dataand provide insights signi/f_icantly streamlined the analytical pro-cess. Finally, it provided insights into the relationship betweenquality scores and alcohol content.

----- Page 9 -----

8M. SUN ET AL.
Figure 6.Conversational machine learning and report generation by LAMBDA. Excerpt from a partial dialogue.Next, we train a set of models to predict wine quality usingLAMBDA. LAMBDA facilitates an interactive analysis process,enabling us to perform tasks such as data processing, featureengineering, model training, parameter tuning, and evaluationthrough a series of guided conversations. Finally, we usedLAMBDA ’s built-in report generation feature to compile aanalysis report, which includes details of the tasks completedin the conversation history. The analysis process, includingthe conversation and the generated report, is presented inFigure 6.As beginner-level users, we /f_irst asked LAMBDA to rec-ommend some models, and it suggested advanced optionslike XGBoost. Next, we tasked LAMBDA with basic datapreprocessing, which it handled correctly. We then trainedand evaluated the recommended models using 5-fold cross-validation, a task LAMBDA performed exceptionally well, evenproviding download links for the resulting models. Finally, weused LAMBDA ’s report generation feature to create a structuredand comprehensive report that eﬀectively captured the keyinsights.This example demonstrates the eﬀectiveness of conversa-tional data agents like ChatGPT and LAMBDA in stream-lining the data visualization and machine learning work-%ow, particularly for users without programming experi-ence.4.2. Case Study 2: Residual Diagnostics andHeteroscedasticity TestingTo examine the ability of LLM-based data agents to performstatistically rigorous regression diagnostics, we promptedLAMBDA and GPT-4o to conduct a linear regression analysisusing the Auto MPG dataset, a tabular data with dimension of398times7. The goal was to predictmpg(miles per gallon)based on vehicle characteristics, notablyhorsepowerandweight. The prompt and response of LAMBDA are detailed intheFigure 7.LAMBDA correctly loaded the dataset, performed appropri-ate preprocessing (e.g., handling non-numeric entries), and /f_ita linear model usingstatsmodels.I tt h e nc o m p u t e da n dvisualized residuals, followed by executing the Breusch-Pagantest for heteroscedasticity. The test output included the LMstatistic and associatedp-value, indicating a strong violation ofthe homoscedasticity assumption.The residual plot visually con/f_irmed increasing residualvariance with larger /f_itted values. LAMBDA also summa-rized next steps, suggesting robust standard errors or modeltransformation to address heteroscedasticity. This exam-ple demonstrates LAMBDA ’s ability to execute, interpret,and communicate statistically meaningful diagnostics in a%exible code-/f_irst environment. Besides, GPT-4o was alsoable to complete the same task successfully; further details

----- Page 10 -----

THE AMERICAN STATISTICIAN9
Figure 7.Partial dialogue from residual diagnostics and heteroscedasticity testing, and bootstrap con/f_idence interval estimation.and chat transcripts can be found in the supplementarymaterials.4.3. Case Study 3: Bootstrap Con/f_idence IntervalsIn this case study, we assessed whether LLM-based data agentscan perform nonparametric inference through bootstrap resam-pling. Using the Wine Quality dataset, the task was to esti-mate the average alcohol content for red wine and construct a95% con/f_idence interval using 1000 bootstrap resamples.Fig-ure 7shows the interaction with LAMBDA for completing thistask.LAMBDA successfully /f_iltered the dataset to isolate redwines, extracted thealcoholvariable, and implemented thebootstrap routine by repeatedly sampling with replacement.It then computed the empirical 2.5th and 97.5th percentilesof the bootstrapped means to form the con/f_idence interval.The agent also produced a histogram showing the boot-strap distribution, overlaid with the CI bounds and samplemean.This case illustrates that LAMBDA is capable of performingrobust uncertainty quanti/f_ication and generating high-qualityvisual explanations without relying on strict parametric assump-tions. GPT-4o also successfully completed this task; its outputsand detailed interactions are included in the supplementarymaterials.We found that diﬀerent prompting may lead to diﬀerences inimplementation details, such as the choice of hyperparametersor types of plots.4.4. Case Study 4: Expandability of Data AgentsIn many situations, we encounter tasks that cannot be handledeﬀectively using LLMs because their training data do not includethe necessary knowledge for such tasks. In these cases, if adata agent is designed to be extensible, manual tool expansionor knowledge integration can address this limitation. In thiscase study, we demonstrate how both the Data Interpreter andLAMBDA leverage integration mechanisms to incorporate addi-tional packages or domain-speci/f_ic knowledge.Tools Integration in Data Interpreter.In this example, our objec-tive is to extract submission deadlines for AI conferences from apublic website1and save the results. We prompted the agent withthe target URL and the desired output format. The agent success-fully identi/f_ied relevant information such as conference namesand deadlines and generated structured output. The completework%ow, including prompt, execution, and results, is shown inFigure 8.1https://aideadlin.es

----- Page 11 -----

10M. SUN ET AL.
Figure 8.Creating and using the customized tool in the Data Interpreter. Excerpt from a partial dialogue.In this example, the Data Interpreter began with an initialplan. For each sub-task, it recommended relevant tools witha score indicating their suitability. The system then decidedwhether to use the suggested tool. For instance, it usedscrape_web_playwrightfor a web-scraping task. Thisiterative recommendation and tool selection process continueduntil all sub-tasks were completed, addressing limitations inLLMs’ built-in abilities and knowledge.Knowledge Integration in LAMBDA.In this example, we considerthe problem of training a Fixed Point Non-Negative NeuralNetwork (FPNNN), which is de/f_ined as a neural network thatmaps nonnegative vectors to nonnegative vectors. We train aFPNNN with MNIST data. First, we integrated the code intothe knowledge base. Then, we de/f_ined the model asCoreanddelineated theCorefunction, which directly accepts param-eters, and theRunnablefunction, which was de/f_ined andexecuted separately.Figure 6presents the con/f_iguration, prompt,and problem-solving process.LAMBDA /f_irst retrieved the relevant code from the knowl-edge base, and then itsCorefunction was presented in thecontext. By modifying the core code, LAMBDA generated thecorrect code and completed the task successfully (Figure 9).5. Challenges and Future DirectionsIn this section, we highlight some challenges and suggest futuredirections in using LLMs or LLM-based data agents for statisti-cal analysis.5.1. Challenges in the Capabilities of LLMsLLMs function as the “brain” of a data agent, interpreting userintent and generating structured plans to carry out data anal-ysis tasks. For a data agent to be eﬀective, it must possessadvanced knowledge in statistics, data science, and program-ming, enabling it to support users throughout the analyticalprocess.Advanced Models.Current state-of-the-art models like GPT-4s h o ws t r o n gp e r f o r m a n c eo nu n d e r g r a d u a t e - l e v e lm a t h e m a t -ics and statistics problems, yet struggle with more advanced,graduate-level tasks (Frieder et al.2023). Additionally, the suc-cess rate of fully automating complete data work%ows withcurrent agents remains low (Cao et al.2024). This suggests thatenhancements in LLMs, particularly in knowledge of statisticsand data analysis, are still needed.Multi-Modality and Reasoning.Ak e yc h a l l e n g ef o rc u r r e n tLLMs lies in processing multi-modal inputs, including charts,tables, and code, which are essential to data analysis work-%ows (Inala et al.2024). Future advancements may improvethe ability to perform reasoning across mixed modalities, suchas generating visualizations by replicating the style of an inputvisualization.5.2. Challenges in Statistical AnalysisIntelligent Statistical Analysis So/f_tware.While established toolssuch as SPSS and R are highly mature, data agents have thepotential to transform statistical analysis through intelligent

----- Page 12 -----

THE AMERICAN STATISTICIAN11
Figure 9.Integrating knowledge of FPNNNs in LAMBDA. Excerpt from a partial dialogue.assistance. To realize this vision, agents must support %exiblepackage integration, facilitate contributions from domainexperts, and remain aligned with evolving programmingecosystems. Such a collaborative framework could accelerateinnovation in the /f_ield. Furthermore, by guiding users andrecommending appropriate methods, data agents can enhanceresearch eﬃciency and expand access to advanced statisticaltechniques.Incorporating Other Large Models into Statistical Analysis.Statistical analysis of complex data is increasingly leveragingrepresentations generated by large models for research purposes.For example, in predicting the tertiary structure of proteins,LLMs can use representations of primary and secondarystructures-capabilities that traditional statistical so/f_tware suchas Matlab and R currently lack. Similarly, in the analysis ofelectronic health records, LLMs are being used to constructmeaningful representations that facilitate downstream analysis.If data agents can eﬀectively harness domain-speci/f_ic knowledgemodels, they have the potential to signi/f_icantly advancestatistical and data science research, enabling more sophisti-cated analyses and fostering deeper insights across scienti/f_icdisciplines.5.3. Challenges in Real-World AdoptionAlthough the data agents have shown great potential in improv-ing the accessibility of data analysis, there are still several chal-lenges that need to be addressed for real-world adoption.Tradeoﬀ Between Hardware and Privacy.First, deploying largelanguage models o/f_ten requires high-performance computingresources. Running these models on CPU-only machines resultsin slow inference. API-based solutions also raise concerns aboutdata privacy and security, as sensitive information may be trans-mitted to external servers. This is especially critical in /f_ieldssuch as healthcare and /f_inance, where data con/f_identiality isparamount. Therefore, developing lightweight, expert-level datascience models that can run eﬃciently on local machines with-out compromising performance is essential.High-concurrency System.H i g h - c o n c u r r e n c ye n v i r o n m e n t spose signi/f_icant scalability issues. In client-server architectureswhere each user session is associated with an isolated sandboxfor secure code execution, the server may experience substantialresource strain under heavy load. Maintaining a large number ofconcurrent sandboxes can overwhelm system resources, leadingto degraded performance or system instability. Therefore, the